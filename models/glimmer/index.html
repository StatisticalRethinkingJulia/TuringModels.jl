<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Glimmer</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Glimmer</h1> </div> <div class=franklin-content > <p>In Statistical Rethinking Edition 1, McElreath shows that the R <code>glimmer</code> package introduces weakly regularizing priors by default. This can sometimes lead to nonsense estimates. To fix it, McElreath uses a very weakly informative prior in model <code>m.good</code>.</p> <h2 id=data ><a href="#data" class=header-anchor >Data</a></h2> <pre><code class=language-julia ># Outcome and predictor almost perfectly associated.
x &#61; repeat&#40;&#91;-1&#93;, 9&#41;; append&#33;&#40;x, repeat&#40;&#91;1&#93;,11&#41;&#41;;
y &#61; repeat&#40;&#91;0&#93;, 10&#41;; append&#33;&#40;y, repeat&#40;&#91;1&#93;,10&#41;&#41;;</code></pre> <h2 id=model ><a href="#model" class=header-anchor >Model</a></h2> <pre><code class=language-julia >using Turing

@model function m_good_stan&#40;x, y&#41;
    α ~ Normal&#40;0, 10&#41;
    β ~ Normal&#40;0, 10&#41;

    logits &#61; α .&#43; β * x

    y .~ BinomialLogit.&#40;1, logits&#41;
end;</code></pre> <h2 id=output ><a href="#output" class=header-anchor >Output</a></h2> <pre><code class=language-julia >chns &#61; sample&#40;m_good_stan&#40;x, y&#41;, NUTS&#40;&#41;, 1000&#41;</code></pre><pre><code class="plaintext code-output">Chains MCMC chain (1000×14×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 5.83 seconds
Compute duration  = 5.83 seconds
parameters        = α, β
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
  parameters      mean       std   naive_se      mcse        ess      rhat   ess_per_sec
      Symbol   Float64   Float64    Float64   Float64    Float64   Float64       Float64

           α   -4.8741    3.7527     0.1187    0.3227   106.1463    0.9990       18.2132
           β    7.6160    3.7005     0.1170    0.3253   105.4194    0.9991       18.0884

Quantiles
  parameters       2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol    Float64   Float64   Float64   Float64   Float64

           α   -13.3681   -7.0493   -4.3679   -1.9088    0.5320
           β     2.3367    4.6830    7.1109    9.8411   15.6855
</code></pre> </p> <pre><code class=language-julia >using StatsPlots

StatsPlots.plot&#40;chns&#41;</code></pre><pre><code class="plaintext code-output">"/home/runner/work/TuringModels.jl/TuringModels.jl/__site/assets/models/glimmer/code/output/chns.svg"</code></pre>
<p> <img src="/TuringModels.jl/assets/models/glimmer/code/output/chns.svg" alt="">
<h2 id=original_output ><a href="#original_output" class=header-anchor >Original output</a></h2>
<pre><code class=language-julia >m_10_x,_results &#61; &quot;
    mean   sd   5.5&#37; 94.5&#37; n_eff Rhat
 a -5.09 4.08 -12.62 -0.25   100 1.00
 b  7.86 4.09   2.96 15.75   104 1.01
&quot;;</code></pre>

<div class=page-foot >
  <div class=copyright >
    <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
    Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: December 15, 2022. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>.
  </div>
</div>
</div>
    
    
        <script src="/TuringModels.jl/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>